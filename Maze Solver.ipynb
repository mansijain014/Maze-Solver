{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "!pip install --user moviepy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting moviepy\n",
      "  Using cached moviepy-1.0.3-py3-none-any.whl\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from moviepy) (4.4.2)\n",
      "Collecting proglog<=1.0.0\n",
      "  Using cached proglog-0.1.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from moviepy) (1.19.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from moviepy) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from moviepy) (2.25.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from moviepy) (2.9.0)\n",
      "Collecting imageio-ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.5-py3-none-win_amd64.whl (22.6 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.25.11)\n",
      "Installing collected packages: proglog, imageio-ffmpeg, moviepy\n",
      "Successfully installed imageio-ffmpeg-0.4.5 moviepy-1.0.3 proglog-0.1.9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import itertools\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "from moviepy.editor import VideoClip\r\n",
    "\r\n",
    "WORLD_HEIGHT = int(input(\"Enter Maze Height: \"))\r\n",
    "WORLD_WIDTH = int(input(\"Enter Maze Width: \"))\r\n",
    "WALL_FRAC = .2\r\n",
    "NUM_WINS = 5\r\n",
    "NUM_LOSE = 10\r\n",
    "\r\n",
    "class GridWorld:\r\n",
    "\r\n",
    "    def __init__(self, world_height=3, world_width=4, discount_factor=.5, default_reward=-.5, wall_penalty=-.6,\r\n",
    "                 win_reward=5., lose_reward=-10., viz=True, patch_side=120, grid_thickness=2, arrow_thickness=3,\r\n",
    "                 wall_locs=[[1, 1], [1, 2]], win_locs=[[0, 3]], lose_locs=[[1, 3]], start_loc=[0, 0],\r\n",
    "                 reset_prob=.2):\r\n",
    "        self.world = np.ones([world_height, world_width]) * default_reward\r\n",
    "        self.reset_prob = reset_prob\r\n",
    "        self.world_height = world_height\r\n",
    "        self.world_width = world_width\r\n",
    "        self.wall_penalty = wall_penalty\r\n",
    "        self.win_reward = win_reward\r\n",
    "        self.lose_reward = lose_reward\r\n",
    "        self.default_reward = default_reward\r\n",
    "        self.discount_factor = discount_factor\r\n",
    "        self.patch_side = patch_side\r\n",
    "        self.grid_thickness = grid_thickness\r\n",
    "        self.arrow_thickness = arrow_thickness\r\n",
    "        self.wall_locs = np.array(wall_locs)\r\n",
    "        self.win_locs = np.array(win_locs)\r\n",
    "        self.lose_locs = np.array(lose_locs)\r\n",
    "        self.at_terminal_state = False\r\n",
    "        self.auto_reset = True\r\n",
    "        self.random_respawn = True\r\n",
    "        self.step = 0\r\n",
    "        self.viz_canvas = None\r\n",
    "        self.viz = viz\r\n",
    "        self.path_color = (128, 128, 128)\r\n",
    "        self.wall_color = (0, 255, 0)\r\n",
    "        self.win_color = (0, 0, 255)\r\n",
    "        self.lose_color = (255, 0, 0)\r\n",
    "        self.world[self.wall_locs[:, 0], self.wall_locs[:, 1]] = self.wall_penalty\r\n",
    "        self.world[self.lose_locs[:, 0], self.lose_locs[:, 1]] = self.lose_reward\r\n",
    "        self.world[self.win_locs[:, 0], self.win_locs[:, 1]] = self.win_reward\r\n",
    "        spawn_condn = lambda loc: self.world[loc[0], loc[1]] == self.default_reward\r\n",
    "        self.spawn_locs = np.array([loc for loc in itertools.product(np.arange(self.world_height),\r\n",
    "                                                                     np.arange(self.world_width))\r\n",
    "                                    if spawn_condn(loc)])\r\n",
    "        self.start_state = np.array(start_loc)\r\n",
    "        self.bot_rc = None\r\n",
    "        self.reset()\r\n",
    "        self.actions = [self.up, self.left, self.right, self.down, self.noop]\r\n",
    "        self.action_labels = ['UP', 'LEFT', 'RIGHT', 'DOWN', 'NOOP']\r\n",
    "        self.q_values = np.ones([self.world.shape[0], self.world.shape[1], len(self.actions)]) * 1. / len(self.actions)\r\n",
    "        if self.viz:\r\n",
    "            self.init_grid_canvas()\r\n",
    "            self.video_out_fpath = 'shm_dqn_gridsolver-' + str(time.time()) + '.mp4'\r\n",
    "            self.clip = VideoClip(self.make_frame, duration=15)\r\n",
    "\r\n",
    "    def make_frame(self, t):\r\n",
    "        self.action()\r\n",
    "        frame = self.highlight_loc(self.viz_canvas, self.bot_rc[0], self.bot_rc[1])\r\n",
    "        return frame\r\n",
    "\r\n",
    "    def check_terminal_state(self):\r\n",
    "        if self.world[self.bot_rc[0], self.bot_rc[1]] == self.lose_reward \\\r\n",
    "                or self.world[self.bot_rc[0], self.bot_rc[1]] == self.win_reward:\r\n",
    "            self.at_terminal_state = True\r\n",
    "            # print('------++++---- TERMINAL STATE ------++++----')\r\n",
    "            # if self.world[self.bot_rc[0], self.bot_rc[1]] == self.win_reward:\r\n",
    "            #     print('GAME WON! :D')\r\n",
    "            # elif self.world[self.bot_rc[0], self.bot_rc[1]] == self.lose_reward:\r\n",
    "            #     print('GAME LOST! :(')\r\n",
    "            if self.auto_reset:\r\n",
    "                self.reset()\r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        # print('Resetting')\r\n",
    "        if not self.random_respawn:\r\n",
    "            self.bot_rc = self.start_state.copy()\r\n",
    "        else:\r\n",
    "            self.bot_rc = self.spawn_locs[np.random.choice(np.arange(len(self.spawn_locs)))].copy()\r\n",
    "        self.at_terminal_state = False\r\n",
    "\r\n",
    "    def up(self):\r\n",
    "        action_idx = 0\r\n",
    "        # print(self.action_labels[action_idx])\r\n",
    "        new_r = self.bot_rc[0] - 1\r\n",
    "        if new_r < 0 or self.world[new_r, self.bot_rc[1]] == self.wall_penalty:\r\n",
    "            return self.wall_penalty, action_idx\r\n",
    "        self.bot_rc[0] = new_r\r\n",
    "        reward = self.world[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        self.check_terminal_state()\r\n",
    "        return reward, action_idx\r\n",
    "\r\n",
    "    def left(self):\r\n",
    "        action_idx = 1\r\n",
    "        # print(self.action_labels[action_idx])\r\n",
    "        new_c = self.bot_rc[1] - 1\r\n",
    "        if new_c < 0 or self.world[self.bot_rc[0], new_c] == self.wall_penalty:\r\n",
    "            return self.wall_penalty, action_idx\r\n",
    "        self.bot_rc[1] = new_c\r\n",
    "        reward = self.world[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        self.check_terminal_state()\r\n",
    "        return reward, action_idx\r\n",
    "\r\n",
    "    def right(self):\r\n",
    "        action_idx = 2\r\n",
    "        # print(self.action_labels[action_idx])\r\n",
    "        new_c = self.bot_rc[1] + 1\r\n",
    "        if new_c >= self.world.shape[1] or self.world[self.bot_rc[0], new_c] == self.wall_penalty:\r\n",
    "            return self.wall_penalty, action_idx\r\n",
    "        self.bot_rc[1] = new_c\r\n",
    "        reward = self.world[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        self.check_terminal_state()\r\n",
    "        return reward, action_idx\r\n",
    "\r\n",
    "    def down(self):\r\n",
    "        action_idx = 3\r\n",
    "        # print(self.action_labels[action_idx])\r\n",
    "        new_r = self.bot_rc[0] + 1\r\n",
    "        if new_r >= self.world.shape[0] or self.world[new_r, self.bot_rc[1]] == self.wall_penalty:\r\n",
    "            return self.wall_penalty, action_idx\r\n",
    "        self.bot_rc[0] = new_r\r\n",
    "        reward = self.world[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        self.check_terminal_state()\r\n",
    "        return reward, action_idx\r\n",
    "\r\n",
    "    def noop(self):\r\n",
    "        action_idx = 4\r\n",
    "        # print(self.action_labels[action_idx])\r\n",
    "        reward = self.world[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        self.check_terminal_state()\r\n",
    "        return reward, action_idx\r\n",
    "\r\n",
    "    def qvals2probs(self, q_vals, epsilon=1e-4):\r\n",
    "        action_probs = q_vals - q_vals.min() + epsilon\r\n",
    "        action_probs = action_probs / action_probs.sum()\r\n",
    "        return action_probs\r\n",
    "\r\n",
    "    def action(self):\r\n",
    "        # print('================ ACTION =================')\r\n",
    "        if self.at_terminal_state:\r\n",
    "            print('At terminal state, please call reset()')\r\n",
    "            exit()\r\n",
    "        # print('Start position:', self.bot_rc)\r\n",
    "        start_bot_rc = self.bot_rc[0], self.bot_rc[1]\r\n",
    "        q_vals = self.q_values[self.bot_rc[0], self.bot_rc[1]]\r\n",
    "        action_probs = self.qvals2probs(q_vals)\r\n",
    "        reward, action_idx = np.random.choice(self.actions, p=action_probs)()\r\n",
    "        # print('End position:', self.bot_rc)\r\n",
    "        # print('Reward:', reward)\r\n",
    "        alpha = np.exp(-self.step / 10e9)\r\n",
    "        self.step += 1\r\n",
    "        qv = (1 - alpha) * q_vals[action_idx] + alpha * (reward + self.discount_factor\r\n",
    "                                                         * self.q_values[self.bot_rc[0], self.bot_rc[1]].max())\r\n",
    "        self.q_values[start_bot_rc[0], start_bot_rc[1], action_idx] = qv\r\n",
    "        if self.viz:\r\n",
    "            self.update_viz(start_bot_rc[0], start_bot_rc[1])\r\n",
    "        if np.random.rand() < self.reset_prob:\r\n",
    "            # print('-----> Randomly resetting to a random spawn point with probability', self.reset_prob)\r\n",
    "            self.reset()\r\n",
    "\r\n",
    "    def highlight_loc(self, viz_in, i, j):\r\n",
    "        starty = i * (self.patch_side + self.grid_thickness)\r\n",
    "        endy = starty + self.patch_side\r\n",
    "        startx = j * (self.patch_side + self.grid_thickness)\r\n",
    "        endx = startx + self.patch_side\r\n",
    "        viz = viz_in.copy()\r\n",
    "        cv2.rectangle(viz, (startx, starty), (endx, endy), (255, 255, 255), thickness=self.grid_thickness)\r\n",
    "        return viz\r\n",
    "\r\n",
    "    def update_viz(self, i, j):\r\n",
    "        starty = i * (self.patch_side + self.grid_thickness)\r\n",
    "        endy = starty + self.patch_side\r\n",
    "        startx = j * (self.patch_side + self.grid_thickness)\r\n",
    "        endx = startx + self.patch_side\r\n",
    "        patch = np.zeros([self.patch_side, self.patch_side, 3]).astype(np.uint8)\r\n",
    "        if self.world[i, j] == self.default_reward:\r\n",
    "            patch[:, :, :] = self.path_color\r\n",
    "        elif self.world[i, j] == self.wall_penalty:\r\n",
    "            patch[:, :, :] = self.wall_color\r\n",
    "        elif self.world[i, j] == self.win_reward:\r\n",
    "            patch[:, :, :] = self.win_color\r\n",
    "        elif self.world[i, j] == self.lose_reward:\r\n",
    "            patch[:, :, :] = self.lose_color\r\n",
    "        if self.world[i, j] == self.default_reward:\r\n",
    "            action_probs = self.qvals2probs(self.q_values[i, j])\r\n",
    "            x_component = action_probs[2] - action_probs[1]\r\n",
    "            y_component = action_probs[0] - action_probs[3]\r\n",
    "            magnitude = 1. - action_probs[-1]\r\n",
    "            s = self.patch_side // 2\r\n",
    "            x_patch = int(s * x_component)\r\n",
    "            y_patch = int(s * y_component)\r\n",
    "            arrow_canvas = np.zeros_like(patch)\r\n",
    "            vx = s + x_patch\r\n",
    "            vy = s - y_patch\r\n",
    "            cv2.arrowedLine(arrow_canvas, (s, s), (vx, vy), (255, 255, 255), thickness=self.arrow_thickness,\r\n",
    "                            tipLength=0.5)\r\n",
    "            gridbox = (magnitude * arrow_canvas + (1 - magnitude) * patch).astype(np.uint8)\r\n",
    "            self.viz_canvas[starty:endy, startx:endx] = gridbox\r\n",
    "        else:\r\n",
    "            self.viz_canvas[starty:endy, startx:endx] = patch\r\n",
    "\r\n",
    "    def init_grid_canvas(self):\r\n",
    "        org_h, org_w = self.world_height, self.world_width\r\n",
    "        viz_w = (self.patch_side * org_w) + (self.grid_thickness * (org_w - 1))\r\n",
    "        viz_h = (self.patch_side * org_h) + (self.grid_thickness * (org_h - 1))\r\n",
    "        self.viz_canvas = np.zeros([viz_h, viz_w, 3]).astype(np.uint8)\r\n",
    "        for i in range(org_h):\r\n",
    "            for j in range(org_w):\r\n",
    "                self.update_viz(i, j)\r\n",
    "\r\n",
    "    def solve(self):\r\n",
    "        if not self.viz:\r\n",
    "            while True:\r\n",
    "                self.action()\r\n",
    "        else:\r\n",
    "            self.clip.write_videofile(self.video_out_fpath, fps=460)\r\n",
    "\r\n",
    "\r\n",
    "def gen_world_config(h, w, wall_frac=.5, num_wins=2, num_lose=3):\r\n",
    "    n = h * w\r\n",
    "    num_wall_blocks = int(wall_frac * n)\r\n",
    "    wall_locs = (np.random.rand(num_wall_blocks, 2) * [h, w]).astype(np.int)\r\n",
    "    win_locs = (np.random.rand(num_wins, 2) * [h, w]).astype(np.int)\r\n",
    "    lose_locs = (np.random.rand(num_lose, 2) * [h, w]).astype(np.int)\r\n",
    "    return wall_locs, win_locs, lose_locs\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    wall_locs, win_locs, lose_locs = gen_world_config(WORLD_HEIGHT, WORLD_WIDTH, WALL_FRAC, NUM_WINS, NUM_LOSE)\r\n",
    "    g = GridWorld(world_height=WORLD_HEIGHT, world_width=WORLD_WIDTH,\r\n",
    "                  wall_locs=wall_locs, win_locs=win_locs, lose_locs=lose_locs, viz=True)\r\n",
    "    g.solve()\r\n",
    "    k = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Moviepy - Building video shm_dqn_gridsolver-1630688926.2455235.mp4.\n",
      "Moviepy - Writing video shm_dqn_gridsolver-1630688926.2455235.mp4\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready shm_dqn_gridsolver-1630688926.2455235.mp4\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "ef7f9a8012d9131766e31894c279374cc63c73121ed4db3b9e67a294a4bf0e74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}